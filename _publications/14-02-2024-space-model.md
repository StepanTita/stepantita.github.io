---
title: "Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs"
collection: publications
permalink: /publication/14-02-2024-space-model
excerpt: 'In this paper, we present a framework that allows for maintaining generalizability, and enhances the performance on the downstream task by utilizing task-specific context attribution'
date: 14-02-2024
venue: 'AAAI Responsible Language Model (ReLM) Workshop'
paperurl: 'http://stytarenko.github.io/files/SpaceModel.pdf'
citation: 'TBD'
---
In this paper, we present a framework that allows for maintaining generalizability, and enhances the performance on the downstream task by utilizing task-specific context attribution

[Download paper here](http://stytarenko.github.io/files/SpaceModel.pdf)

Recommended citation: TBD
